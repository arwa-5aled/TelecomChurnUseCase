{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a076bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'sh' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!curl -fsSL https://ollama.com/install.sh | sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c466759d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "get_ipython().system = os.system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a13a53d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!ollama serve &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c392957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!ollama run gemma3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60a7d365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "651611f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_community.chat_models import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19bd892d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "system_prompt = f\"\"\"\n",
    "You are a customer churn prediction assistant.\n",
    "Extract customer features in the exact format:\n",
    "\n",
    "customerID: string, use \"unknown\" if not provided\n",
    "gender: \"Male\" or \"Female\"\n",
    "Senior_Citizen : 0 or 1\n",
    "Is_Married: \"Yes\" or \"No\"\n",
    "Dependents: \"Yes\" or \"No\"\n",
    "tenure: integer\n",
    "Phone_Service: \"Yes\" or \"No\"\n",
    "Dual: \"Yes\" or \"No\"\n",
    "Internet_Service: \"DSL\", \"Fiber optic\", or \"No\"\n",
    "Online_Security: \"Yes\" or \"No\"\n",
    "Online_Backup: \"Yes\" or \"No\"\n",
    "Device_Protection: \"Yes\" or \"No\"\n",
    "Tech_Support: \"Yes\" or \"No\"\n",
    "Streaming_TV: \"Yes\" or \"No\"\n",
    "Streaming_Movies: \"Yes\" or \"No\"\n",
    "Contract: \"Month-to-month\", \"One year\", \"Two year\"\n",
    "Paperless_Billing: \"Yes\" or \"No\"\n",
    "Payment_Method: \"Electronic check\", \"Mailed check\", \"Bank transfer (automatic)\", \"Credit card (automatic)\"\n",
    "Monthly_Charges: float\n",
    "Total_Charges: float\n",
    "\n",
    "Return ONLY a Python dictionary with these exact keys:\n",
    "customerID, gender, Senior_Citizen , Is_Married, Dependents,\n",
    "tenure, Phone_Service, Dual, Internet_Service, Online_Security,\n",
    "Online_Backup, Device_Protection, Tech_Support, Streaming_TV,\n",
    "Streaming_Movies, Contract, Paperless_Billing, Payment_Method,\n",
    "Monthly_Charges, Total_Charges\n",
    "\n",
    "- Fill missing features with None (or leave missing if you want NaN) except customerID fill it with unKnown .\n",
    "- Do NOT add explanations or text outside the dictionary. \n",
    "- Use this format: \n",
    "{{{{\"customerID\": \"unknown\", \"gender\": \"Female\", \"Senior_Citizen \": 0, ...}}}}\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b062bd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_prompt= \"I have a female customer  , 45 years old, married, no dependents, no internet Service, has phone service, monthly charges 75, total charges 1200 , Paperless_Billing yes, contract month to month, payment method is electronic check, tenure 16 months, no online security, no online backup, no device protection, no tech support, no streaming TV, no streaming movies. What are her features?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5a28baf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "{\n",
      "\"customerID\": \"unknown\",\n",
      "\"gender\": \"Female\",\n",
      "\"Senior_Citizen\": 0,\n",
      "\"Is_Married\": \"Yes\",\n",
      "\"Dependents\": \"No\",\n",
      "\"tenure\": 16,\n",
      "\"Phone_Service\": \"Yes\",\n",
      "\"Dual\": \"No\",\n",
      "\"Internet_Service\": \"No\",\n",
      "\"Online_Security\": \"No\",\n",
      "\"Online_Backup\": \"No\",\n",
      "\"Device_Protection\": \"No\",\n",
      "\"Tech_Support\": \"No\",\n",
      "\"Streaming_TV\": \"No\",\n",
      "\"Streaming_Movies\": \"No\",\n",
      "\"Contract\": \"Month-to-month\",\n",
      "\"Paperless_Billing\": \"Yes\",\n",
      "\"Payment_Method\": \"Electronic check\",\n",
      "\"Monthly_Charges\": 75.0,\n",
      "\"Total_Charges\": 1200.0\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{customer_paragraph}\")\n",
    "])\n",
    "\n",
    "# --- Format the prompt with the human input ---\n",
    "final_prompt = chat_template.format_messages(customer_paragraph=human_prompt)\n",
    "llm = ChatOllama(model=\"gemma3\")\n",
    "response = llm(final_prompt)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47e85f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(response.content))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "021f3c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "{\n",
      "    \"customerID\": \"unknown\",\n",
      "    \"gender\": \"Female\",\n",
      "    \"Senior_Citizen\": 0,\n",
      "    \"Is_Married\": \"Yes\",\n",
      "    \"Dependents\": \"No\",\n",
      "    \"tenure\": None,\n",
      "    \"Phone_Service\": \"Yes\",\n",
      "    \"Dual\": None,\n",
      "    \"Internet_Service\": \"No\",\n",
      "    \"Online_Security\": None,\n",
      "    \"Online_Backup\": None,\n",
      "    \"Device_Protection\": None,\n",
      "    \"Tech_Support\": None,\n",
      "    \"Streaming_TV\": None,\n",
      "    \"Streaming_Movies\": None,\n",
      "    \"Contract\": None,\n",
      "    \"Paperless_Billing\": None,\n",
      "    \"Payment_Method\": None,\n",
      "    \"Monthly_Ch\n"
     ]
    }
   ],
   "source": [
    "print(response.content[:500])  # see the first 500 characters\n",
    "  # check if it’s empty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "606e9182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING WITH SAMPLE DATA:\n",
      "==================================================\n",
      "DEBUGGING LLM OUTPUT\n",
      "==================================================\n",
      "Raw output type: <class 'str'>\n",
      "Raw output length: 492\n",
      "Raw output (first 200 chars): '```python\\n{\\n\"customerID\": \"unknown\",\\n\"gender\": \"Female\",\\n\"Senior_Citizen\": 0,\\n\"Is_Married\": \"Yes\",\\n\"Dependents\": \"No\",\\n\"tenure\": 16,\\n\"Phone_Service\": \"Yes\",\\n\"Dual\": \"No\",\\n\"Internet_Service\": \"No\",\\n\"On'\n",
      "\n",
      "Found JSON-like content: {\n",
      "\"customerID\": \"unknown\",\n",
      "\"gender\": \"Female\",\n",
      "\"Senior_Citizen\": 0,\n",
      "\"Is_Married\": \"Yes\",\n",
      "\"Dependents...\n",
      "\n",
      "Trying method: JSON with None->null replacement\n",
      "✅ SUCCESS with JSON with None->null replacement\n",
      "Result type: <class 'dict'>\n",
      "Result keys: ['customerID', 'gender', 'Senior_Citizen', 'Is_Married', 'Dependents', 'tenure', 'Phone_Service', 'Dual', 'Internet_Service', 'Online_Security', 'Online_Backup', 'Device_Protection', 'Tech_Support', 'Streaming_TV', 'Streaming_Movies', 'Contract', 'Paperless_Billing', 'Payment_Method', 'Monthly_Charges', 'Total_Charges']\n",
      "\n",
      "✅ Final result: {'customerID': 'unknown', 'gender': 'Female', 'Senior_Citizen': 0, 'Is_Married': 'Yes', 'Dependents': 'No', 'tenure': 16, 'Phone_Service': 'Yes', 'Dual': 'No', 'Internet_Service': 'No', 'Online_Security': 'No', 'Online_Backup': 'No', 'Device_Protection': 'No', 'Tech_Support': 'No', 'Streaming_TV': 'No', 'Streaming_Movies': 'No', 'Contract': 'Month-to-month', 'Paperless_Billing': 'Yes', 'Payment_Method': 'Electronic check', 'Monthly_Charges': 75.0, 'Total_Charges': 1200.0}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import ast\n",
    "\n",
    "def debug_and_convert_llm_output(llm_string):\n",
    "    \"\"\"\n",
    "    Debug and convert LLM output to dictionary with detailed error handling\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*50)\n",
    "    print(\"DEBUGGING LLM OUTPUT\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Step 1: Check what we received\n",
    "    print(f\"Raw output type: {type(llm_string)}\")\n",
    "    print(f\"Raw output length: {len(llm_string) if llm_string else 0}\")\n",
    "    print(f\"Raw output (first 200 chars): {repr(llm_string[:200])}\")\n",
    "    \n",
    "    if not llm_string or len(llm_string.strip()) == 0:\n",
    "        print(\"ERROR: Empty or None input!\")\n",
    "        return None\n",
    "    \n",
    "    # Step 2: Clean the string\n",
    "    cleaned = llm_string.strip()\n",
    "    \n",
    "    # Step 3: Try to extract JSON from the response\n",
    "    # Look for JSON-like patterns (starts with { and ends with })\n",
    "    json_match = re.search(r'\\{.*\\}', cleaned, re.DOTALL)\n",
    "    \n",
    "    if json_match:\n",
    "        json_candidate = json_match.group(0)\n",
    "        print(f\"\\nFound JSON-like content: {json_candidate[:100]}...\")\n",
    "    else:\n",
    "        print(f\"\\nNo JSON pattern found. Full content:\\n{cleaned}\")\n",
    "        # Try to find any dictionary-like content\n",
    "        dict_patterns = [\n",
    "            r'```python\\s*(\\{.*?\\})\\s*```',  # Python code blocks\n",
    "            r'```json\\s*(\\{.*?\\})\\s*```',    # JSON code blocks  \n",
    "            r'```\\s*(\\{.*?\\})\\s*```',        # Generic code blocks\n",
    "        ]\n",
    "        \n",
    "        for pattern in dict_patterns:\n",
    "            match = re.search(pattern, cleaned, re.DOTALL)\n",
    "            if match:\n",
    "                json_candidate = match.group(1)\n",
    "                print(f\"Found content in code block: {json_candidate[:100]}...\")\n",
    "                break\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    # Step 4: Try different conversion methods\n",
    "    conversion_methods = [\n",
    "        (\"JSON with None->null replacement\", lambda x: json.loads(x.replace('None', 'null').replace('True', 'true').replace('False', 'false'))),\n",
    "        (\"AST literal eval\", ast.literal_eval),\n",
    "        (\"JSON direct\", json.loads),\n",
    "        (\"Eval (unsafe)\", eval),\n",
    "    ]\n",
    "    \n",
    "    for method_name, method_func in conversion_methods:\n",
    "        try:\n",
    "            print(f\"\\nTrying method: {method_name}\")\n",
    "            result = method_func(json_candidate)\n",
    "            print(f\"✅ SUCCESS with {method_name}\")\n",
    "            print(f\"Result type: {type(result)}\")\n",
    "            print(f\"Result keys: {list(result.keys()) if isinstance(result, dict) else 'Not a dict'}\")\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed with {method_name}: {str(e)}\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "def robust_llm_to_dict(llm_string):\n",
    "    \"\"\"\n",
    "    More robust conversion function\n",
    "    \"\"\"\n",
    "    if not llm_string:\n",
    "        return None\n",
    "    \n",
    "    # Clean the input\n",
    "    cleaned = str(llm_string).strip()\n",
    "    \n",
    "    # Extract JSON-like content\n",
    "    patterns = [\n",
    "        r'\\{[^{}]*(?:\\{[^{}]*\\}[^{}]*)*\\}',  # Simple nested braces\n",
    "        r'\\{.*\\}',  # Any content between braces\n",
    "    ]\n",
    "    \n",
    "    json_content = None\n",
    "    for pattern in patterns:\n",
    "        matches = re.findall(pattern, cleaned, re.DOTALL)\n",
    "        if matches:\n",
    "            # Take the longest match (likely the most complete)\n",
    "            json_content = max(matches, key=len)\n",
    "            break\n",
    "    \n",
    "    if not json_content:\n",
    "        return None\n",
    "    \n",
    "    # Try conversion methods in order of preference\n",
    "    methods = [\n",
    "        lambda x: json.loads(re.sub(r'\\b(None|True|False)\\b', \n",
    "                                   lambda m: {'None': 'null', 'True': 'true', 'False': 'false'}[m.group()], x)),\n",
    "        ast.literal_eval,\n",
    "    ]\n",
    "    \n",
    "    for method in methods:\n",
    "        try:\n",
    "            result = method(json_content)\n",
    "            if isinstance(result, dict):\n",
    "                return result\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Test with your actual response\n",
    "# Replace this with your actual response.content\n",
    "response = response.content\n",
    "\n",
    "print(\"TESTING WITH SAMPLE DATA:\")\n",
    "result = debug_and_convert_llm_output(response)\n",
    "if result:\n",
    "    print(f\"\\n✅ Final result: {result}\")\n",
    "else:\n",
    "    print(\"\\n❌ Could not convert to dictionary\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c1b9c830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the source folder to sys.path\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "\n",
    "# Now you can import functions from model.py\n",
    "from model import classify_customer\n",
    "\n",
    "final_result = classify_customer(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3a551888",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import model\n",
    "importlib.reload(model)\n",
    "\n",
    "from model import classify_customer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0ef0dabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Customer_ID': 'unknown', 'prediction': 0, 'Reasons': ['multi__Internet_Service_No ↓ (impact=-4.096)', 'bin__Phone_Service ↑ (impact=1.245)', 'num__Monthly_Charges ↓ (impact=-0.795)', 'bin__Streaming_Movies ↑ (impact=0.599)', 'bin__Streaming_TV ↑ (impact=0.597)']}\n"
     ]
    }
   ],
   "source": [
    "print(final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0e374104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_marketing_prompt(output: dict) -> str:\n",
    "    pred = \"will churn\" if output[\"prediction\"] == 1 else \"will stay\"\n",
    "  \n",
    "    \n",
    "    reasons = \"\\n\".join([f\"- {r}\" for r in output[\"Reasons\"]])\n",
    "    \n",
    "    return f\"\"\"\n",
    "You are a customer success advisor. \n",
    "The model predicts that this customer {pred} .\n",
    "\n",
    "Here are the technical factors:\n",
    "{reasons}\n",
    "\n",
    "Now explain to a marketing team in very natural business language:\n",
    "- Why the customer is likely to {pred}\n",
    "- What the key reasons are, phrased in everyday terms\n",
    "- Keep the explanation clear, short, and actionable\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dde7a449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay team, let’s talk about this customer – we’ve got a good prediction they’re going to stick around. \n",
      "\n",
      "Basically, the model is saying they’re pretty happy with us right now. The biggest factors keeping them loyal are that they’re using our internet service and that their monthly bill is relatively low. \n",
      "\n",
      "However, we should be aware that they’re actively using our streaming TV service, which is a positive sign, but not a huge driver of loyalty.  It's worth noting they're also using our phone service – that’s holding them steady. \n",
      "\n",
      "**Actionable takeaway:** Let’s focus on reinforcing the value of our internet service – maybe a quick check-in to make sure they’re getting the most out of it. We can also subtly highlight the convenience of our streaming options, but let’s not overemphasize that compared to their internet usage. \n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "Do you want me to tailor this explanation for a specific channel (e.g., email, phone call)?\n"
     ]
    }
   ],
   "source": [
    "system_prompt_response = (\n",
    "    \"You are a helpful assistant that explains customer churn predictions \"\n",
    "    \"in plain, natural language for a marketing team.\"\n",
    ")\n",
    "\n",
    "# Use the marketing-friendly prompt builder instead of the old one\n",
    "human_prompt_response = build_marketing_prompt(final_result)\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt_response),\n",
    "    (\"human\", \"{customer_paragraph}\")\n",
    "])\n",
    "\n",
    "final_reason_prompt = chat_template.format_messages(\n",
    "    customer_paragraph=human_prompt_response\n",
    ")\n",
    "\n",
    "llm = ChatOllama(model=\"gemma3\")\n",
    "reasons = llm(final_reason_prompt)\n",
    "\n",
    "print(reasons.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7590ef8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e82f584",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
